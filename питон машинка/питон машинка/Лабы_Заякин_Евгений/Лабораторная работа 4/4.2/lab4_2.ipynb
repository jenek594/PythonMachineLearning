{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a69344649e7c294c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Для выполнения практического задания будем использовать данные о диабете у женщин. \n",
    "Данные хранятся в файле «diabetes.csv».\n",
    "Данные содержат следующие характеристики:\n",
    "1.\tPregnancies – число случаев беременности\n",
    "2.\tGlucose – концентрация глюкозы в крови\n",
    "3.\tBloodPressure – артериальное диастолическое давление (мм рт. ст.)\n",
    "4.\tSkinThickness – толщина кожной складки трехглавой мышцы (мм)\n",
    "5.\tInsulin – 2-х часовой сывороточный инсулин\n",
    "6.\tBMI – индекс массы тела\n",
    "7.\tDiabetesPedigreeFunction – числовой параметр наследственности диабета\n",
    "8.\tAge – возраст\n",
    "Outcome – целевая переменная: 1 – наличие заболевания, 0 – отсутствие"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d9189cc07a31f3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Задача: построить линейные модели (логистическая регрессия, метод опорных векторов), определяющие есть или нет заболевание по набору характеристик 1-8. Сравнить качество моделей.\n",
    "\n",
    "Для каждой модели:\n",
    "1.\tЗагрузите данные в DataFrame с помощью функции read_csv библиотеки pandas.\n",
    "2.\tКак наблюдения (объекты) распределились по классам? \n",
    "Сколько наблюдений в каждом классе? Для ответа на вопрос используйте метод\n",
    "value_counts().\n",
    "3.\tРазделите данные на признаки и ответы, а затем на обучающую и тестовую выборки. \n",
    "4.\tОбучите модель. \n",
    "5.\tОцените качество модели на тестовой выборке. \n",
    "Используйте для этого функцию classification_report. Что можно сказать о модели?\n",
    "6.\tСтандартизируйте данные и постройте модель на стандартизированных данных. Используйте для стандартизации класс StandardScaler. Оцените\n",
    "качество модели с помощью classification_report. Улучшилась ли модель?\n",
    "7.\tВоспользуйтесь перекрестной проверкой, чтобы оценить качество моделей. Используйте функцию cross_val_score.\n",
    "Какой вывод можно сделать?\n",
    "8. Если усреднённые показатели качества линейной модели для нестандартизованных и стандиртизованных данных почти равны, то следует для улучшения качества SVM-модели брать другое значение kernel. Найдите наилучший вариант. Для модели логистической регрессии организуйте поиск по сетке, используя \n",
    "from sklearn.model_selection import GridSearchCV.\n",
    "9.\tРешите эту задачу с помощью метода k ближайших соседей, подобрав оптимальное значение k.\n",
    "10.\tПостройте дерево решений с помощью класса DecisionTreeClassifier.\n",
    "11.\tОцените качество модели с помощью функции classification_report.\n",
    "12.\tПодберите оптимальное значение гиперпараметра max_depth с помощью поиска по сетке (класс GridSearchCV).\n",
    "13.\t Обучите модель с оптимальным max_depth и оцените результат.\n",
    "14.\t Сравните все модели и сделайте выводы.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62341ca7aa3177a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:32:34.158428600Z",
     "start_time": "2024-04-09T12:32:34.004797700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adc2e30b5db6a358",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:32:34.158428600Z",
     "start_time": "2024-04-09T12:32:34.026931400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome\n",
      "0    500\n",
      "1    268\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv(\"diabetes.csv\") # Загрузка данных\n",
    "\n",
    "class_distribution = data['Outcome'].value_counts() # количество наблюдений для каждого целевого значения\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bb2ea0bfe113f3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:32:34.390171900Z",
     "start_time": "2024-04-09T12:32:34.058183900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80        99\n",
      "           1       0.64      0.67      0.65        55\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.73      0.73       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n",
      "Метод опорных векторов:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83        99\n",
      "           1       0.72      0.56      0.63        55\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.72      0.73       154\n",
      "weighted avg       0.76      0.77      0.76       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = data.drop('Outcome', axis=1)     # делим на признки и целевую\n",
    "y = data['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Разделение на обучающую и тестовую выборки\n",
    "logreg_model = LogisticRegression(max_iter=1000)\n",
    "logreg_model.fit(X_train, y_train)                  # Создание и обучение модели логистической регрессии\n",
    "\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)             # Создание и обучение модели SVM\n",
    "\n",
    "print(\"Логистическая регрессия:\")\n",
    "print(classification_report(y_test, logreg_model.predict(X_test)))  # Оценка качества модели логистической регрессии\n",
    "\n",
    "# 0 видит лучше, с 1 больше ошибок\n",
    "\n",
    "print(\"Метод опорных векторов:\")\n",
    "print(classification_report(y_test, svm_model.predict(X_test)))     # Оценка качества модели SVM\n",
    "\n",
    "# 0 видит также лучше, с 1 больше ошибок\n",
    "\n",
    "#Монжо предпложить что это изза того что 0 было гораздо больше чем 1 в выборках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49148b7c68fe87ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:32:34.543783700Z",
     "start_time": "2024-04-09T12:32:34.405783200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия (Стандартизированные данные):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81        99\n",
      "           1       0.65      0.67      0.66        55\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.74      0.73       154\n",
      "weighted avg       0.76      0.75      0.75       154\n",
      "\n",
      "Метод опорных векторов (Стандартизированные данные):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80        99\n",
      "           1       0.65      0.56      0.60        55\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.71      0.70      0.70       154\n",
      "weighted avg       0.73      0.73      0.73       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()   # Стандартизация данных\n",
    "X_train_scaled = scaler.fit_transform(X_train)  \n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#делаем тоже самое тооль уже для станадртизованных\n",
    "logreg_model_scaled = LogisticRegression()\n",
    "logreg_model_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "svm_model_scaled = SVC()\n",
    "svm_model_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "print(\"Логистическая регрессия (Стандартизированные данные):\")\n",
    "print(classification_report(y_test, logreg_model_scaled.predict(X_test_scaled)))\n",
    "# Улучшилась точность, полнота и F1-мера для класса 0.\n",
    "\n",
    "print(\"Метод опорных векторов (Стандартизированные данные):\")\n",
    "print(classification_report(y_test, svm_model_scaled.predict(X_test_scaled)))\n",
    "# Полнота для класса 0 увеличилась, но точность и полнота для класса 1 уменьшились."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cd3d46ace2e85f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:32:35.029244400Z",
     "start_time": "2024-04-09T12:32:34.543783700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценки перекрестной проверки логистической регрессии: [0.77272727 0.74675325 0.75324675 0.81045752 0.77777778]\n",
      "Оценки перекрестной проверки метода опорных векторов: [0.74675325 0.73376623 0.77272727 0.79084967 0.75163399]\n",
      "Средняя точность для логистической: 0.76\n",
      "Средняя точность для svm: 0.77\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logreg_scores = cross_val_score(logreg_model, X, y, cv=5) # Перекрестная проверка для логистической регрессии\n",
    "\n",
    "svm_scores = cross_val_score(svm_model, X, y, cv=5) # Перекрестная проверка для SVM\n",
    "\n",
    "print(\"Оценки перекрестной проверки логистической регрессии:\", logreg_scores)\n",
    "print(\"Оценки перекрестной проверки метода опорных векторов:\", svm_scores)\n",
    "print(\"Средняя точность для логистической: {:.2f}\".format(svm_scores.mean()))\n",
    "print(\"Средняя точность для svm: {:.2f}\".format(logreg_scores.mean()))\n",
    "# точность почти не отличается, но все таки svm немного лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83a9d6319d103719",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T12:32:43.005872300Z",
     "start_time": "2024-04-09T12:32:35.029244400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие параметры: {'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Определение параметров для перебора\n",
    "param_grid = {'kernel': ['linear', 'rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "# Создание экземпляра SVM-модели\n",
    "svm_model = SVC()\n",
    "\n",
    "# Создание объекта GridSearchCV\n",
    "grid_search = GridSearchCV(svm_model, param_grid, cv=5)\n",
    "\n",
    "# Обучение модели\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Вывод наилучших параметров\n",
    "print(\"Наилучшие параметры:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f41f3282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшее значение параметра k: 11\n",
      "Соответствующее качество модели (средняя точность на кросс-валидации): 0.7606024256963881\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_neighbors': range(1, 21)}# Определим диапазон значений параметра k\n",
    "knn_model = KNeighborsClassifier()# Создадим модель k ближайших соседей\n",
    "grid_search = GridSearchCV(knn_model, param_grid, cv=5, scoring='accuracy') # Создадим объект GridSearchCV\n",
    "grid_search.fit(X_train_scaled, y_train)    # Обучим модель на обучающих данных\n",
    "best_k = grid_search.best_params_['n_neighbors']    # Найдем наилучший параметр k и соответствующее качество модели\n",
    "best_score = grid_search.best_score_\n",
    "knn_model_scaled = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_model_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict using k-nearest neighbors model\n",
    "y_pred_knn_scaled = knn_model_scaled.predict(X_test_scaled)\n",
    "print(\"Наилучшее значение параметра k:\", best_k)\n",
    "print(\"Соответствующее качество модели (средняя точность на кросс-валидации):\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05543123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшее значение параметра max_depth: 3\n",
      "Соответствующее качество модели (средняя точность на кросс-валидации): 0.7573903771824604\n"
     ]
    }
   ],
   "source": [
    "tree_model = DecisionTreeClassifier()# Создадим модель дерева решений\n",
    "param_grid = {'max_depth': range(1, 11)}# Определим диапазон значений параметра max_depth\n",
    "grid_search_tree = GridSearchCV(tree_model, param_grid, cv=5, scoring='accuracy')# Создадим объект GridSearchCV\n",
    "grid_search_tree.fit(X_train_scaled, y_train)# Обучим модель на обучающих данных\n",
    "best_max_depth = grid_search_tree.best_params_['max_depth'] # Найдем наилучшее значение параметра max_depth и соответствующее качество модели\n",
    "best_score_tree = grid_search_tree.best_score_\n",
    "\n",
    "print(\"Наилучшее значение параметра max_depth:\", best_max_depth)\n",
    "print(\"Соответствующее качество модели (средняя точность на кросс-валидации):\", best_score_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33ee4b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82        99\n",
      "           1       0.68      0.62      0.65        55\n",
      "\n",
      "    accuracy                           0.76       154\n",
      "   macro avg       0.74      0.73      0.73       154\n",
      "weighted avg       0.76      0.76      0.76       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimal_tree_model = DecisionTreeClassifier(max_depth=best_max_depth) # Создадим модель дерева решений с оптимальным значением max_depth\n",
    "optimal_tree_model.fit(X_train_scaled, y_train) # Обучим модель на обучающих данных\n",
    "y_pred_tree = optimal_tree_model.predict(X_test_scaled) # Предскажем значения на тестовых данных\n",
    "\n",
    "print(classification_report(y_test, y_pred_tree)) # Выведем отчет классификации\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c105212c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81        99\n",
      "           1       0.65      0.67      0.66        55\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.74      0.73       154\n",
      "weighted avg       0.76      0.75      0.75       154\n",
      "\n",
      "SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80        99\n",
      "           1       0.65      0.56      0.60        55\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.71      0.70      0.70       154\n",
      "weighted avg       0.73      0.73      0.73       154\n",
      "\n",
      "K ближайших соседей:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.78        99\n",
      "           1       0.60      0.56      0.58        55\n",
      "\n",
      "    accuracy                           0.71       154\n",
      "   macro avg       0.68      0.68      0.68       154\n",
      "weighted avg       0.70      0.71      0.71       154\n",
      "\n",
      "Дерево решений:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82        99\n",
      "           1       0.68      0.62      0.65        55\n",
      "\n",
      "    accuracy                           0.76       154\n",
      "   macro avg       0.74      0.73      0.73       154\n",
      "weighted avg       0.76      0.76      0.76       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Сравнение моделей и вывод результатов\n",
    "print(\"Логистическая регрессия:\")\n",
    "print(classification_report(y_test, logreg_model_scaled.predict(X_test_scaled)))\n",
    "print(\"SVM:\")\n",
    "print(classification_report(y_test, svm_model_scaled.predict(X_test_scaled)))\n",
    "print(\"K ближайших соседей:\")\n",
    "print(classification_report(y_test, y_pred_knn_scaled))\n",
    "print(\"Дерево решений:\")\n",
    "print(classification_report(y_test, y_pred_tree))\n",
    "\n",
    "\n",
    "# Логистическая регрессия и метод опорных векторов (SVM) показали схожие результаты по всем метрикам, как для нестандартизированных, \n",
    "# так и для стандартизированных данных.\n",
    "# При стандартизации данных метрики качества моделей незначительно улучшились для логистической регрессии, но ухудшились для SVM.\n",
    "\n",
    "# При использовании оптимальных параметров (ядро 'rbf' для SVM и количество соседей k=11 для k-ближайших соседей) удалось достичь близких\n",
    "# результатов к базовым моделям без настройки гиперпараметров.\n",
    "\n",
    "# Для модели дерева решений была найдена оптимальная глубина дерева max_depth=3 с помощью кросс-валидации. Модель дерева решений показала \n",
    "# результаты, сопоставимые с другими моделями, хотя и несколько ниже по некоторым метрикам.\n",
    "\n",
    "# Несмотря на то, что все модели достигли средней точности около 0.75-0.77, стоит отметить, что задача классификации довольно сложная из-за \n",
    "# дисбаланса классов (268 положительных примеров против 500 отрицательных), что может сказаться на качестве моделей."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
